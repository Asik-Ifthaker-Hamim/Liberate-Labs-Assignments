{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama3-8b-8192\",api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', \"Hello, world! It's great to meet you! Is there something I can help you with, or would you like to chat about something in particular?\")\n",
      "('additional_kwargs', {})\n",
      "('response_metadata', {'token_usage': {'completion_tokens': 32, 'prompt_tokens': 14, 'total_tokens': 46, 'completion_time': 0.026666667, 'prompt_time': 0.004990421, 'queue_time': 0.08938077300000001, 'total_time': 0.031657088}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None})\n",
      "('type', 'ai')\n",
      "('name', None)\n",
      "('id', 'run-fd661904-6af6-4d22-b6ab-4b11b181f51e-0')\n",
      "('example', False)\n",
      "('tool_calls', [])\n",
      "('invalid_tool_calls', [])\n",
      "('usage_metadata', {'input_tokens': 14, 'output_tokens': 32, 'total_tokens': 46})\n"
     ]
    }
   ],
   "source": [
    "# Example invocation (assuming `value` is a response dictionary from Langchain)\n",
    "value = model.invoke(\"Hello, world!\")\n",
    "for x in value:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', \"I'd be happy to help! However, I'm a large language model, I don't have have access to real-time information about the current temperature. But I can suggest a few options to help you find out the current temperature:\\n\\n1. Check your local weather app: You can download a weather app on your phone or check the weather forecast on your computer to get the current temperature in your area.\\n2. Check online weather websites: You can visit websites like AccuWeather, Weather.com, or the National Weather Service to get the current temperature and other weather information.\\n3. Ask Siri or Google Assistant: If you have a virtual assistant like Siri or Google Assistant, you can ask them to tell you the current temperature in your area.\\n\\nI hope that helps!\")\n",
      "('additional_kwargs', {})\n",
      "('response_metadata', {'token_usage': {'completion_tokens': 155, 'prompt_tokens': 16, 'total_tokens': 171, 'completion_time': 0.129166667, 'prompt_time': 0.002358586, 'queue_time': 0.019226612, 'total_time': 0.131525253}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None})\n",
      "('type', 'ai')\n",
      "('name', None)\n",
      "('id', 'run-327794be-c598-406a-8d69-ab64c86a4036-0')\n",
      "('example', False)\n",
      "('tool_calls', [])\n",
      "('invalid_tool_calls', [])\n",
      "('usage_metadata', {'input_tokens': 16, 'output_tokens': 155, 'total_tokens': 171})\n"
     ]
    }
   ],
   "source": [
    "# Example invocation (assuming `value` is a response dictionary from Langchain)\n",
    "value = model.invoke(\"Todays Temperatur please\")\n",
    "for x in value:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\user\\miniforge3\\lib\\site-packages (0.3.17)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain) (0.3.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain) (0.3.4)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain) (2.0.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\miniforge3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\miniforge3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\miniforge3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\miniforge3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\miniforge3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\miniforge3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\miniforge3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\user\\miniforge3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\miniforge3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\miniforge3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\miniforge3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniforge3\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniforge3\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniforge3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\miniforge3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\miniforge3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\miniforge3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\miniforge3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\miniforge3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\miniforge3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode?\n",
      "\n",
      "Because light attracts bugs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\"If I tell you a category, tell me a joke\"),\n",
    "    AIMessage(\"Ok.\"),\n",
    "    HumanMessage(\"Computer Science\")\n",
    "]\n",
    "\n",
    "# Assuming the ChatGroq client is compatible with the message format you're passing\n",
    "client = ChatGroq(model=\"llama3-8b-8192\", api_key=\"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\")\n",
    "\n",
    "# Correctly invoking the model\n",
    "response = client.invoke(messages)\n",
    "\n",
    "# Print the entire response to debug and confirm its structure\n",
    "print(response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why do programmers prefer dark mode?\\n\\nBecause light attracts bugs.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 35, 'total_tokens': 48, 'completion_time': 0.010833333, 'prompt_time': 0.006582868, 'queue_time': 0.034274559, 'total_time': 0.017416201}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-6b6e918b-99bf-48ea-a7d4-83e4c3cd8ca2-0', usage_metadata={'input_tokens': 35, 'output_tokens': 13, 'total_tokens': 48})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata['token_usage']['completion_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata['token_usage']['prompt_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why do programmers prefer dark mode?\\n\\nBecause light attracts bugs.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 35, 'total_tokens': 48, 'completion_time': 0.010833333, 'prompt_time': 0.006582868, 'queue_time': 0.034274559, 'total_time': 0.017416201}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-6b6e918b-99bf-48ea-a7d4-83e4c3cd8ca2-0', usage_metadata={'input_tokens': 35, 'output_tokens': 13, 'total_tokens': 48})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import rich\n",
    "\n",
    "# Weather function to retrieve the current temperature\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m&hourly=temperature_2m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for invoking weather API\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"latitude\": {\"type\": \"number\"},\n",
    "                \"longitude\": {\"type\": \"number\"}\n",
    "            },\n",
    "            \"required\": [\"latitude\", \"longitude\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}]\n",
    "\n",
    "# Initialize client and bind tools (make sure your client is properly initialized)\n",
    "client = client.bind_tools(tools=tools)\n",
    "\n",
    "# Step 1: User asks about the weather\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Chittagong today?\"}]\n",
    "\n",
    "# Step 2: Assistant replies with \"Ok, let me check.\"\n",
    "completion = client.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'tool_calls'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_htsq'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"latitude\":22.3433,\"longitude\":91.8333}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'get_weather'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">943</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1022</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.065833333</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.113803877</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'queue_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.020066641999999996</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17963721</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llama3-8b-8192'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fp_6a6771ae9c'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool_calls'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-55abe07f-cc47-427a-b237-7a004564bf7c-0'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'get_weather'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'latitude'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.3433</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'longitude'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91.8333</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_htsq'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool_call'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">943</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1022</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'tool_calls'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'id'\u001b[0m: \u001b[32m'call_htsq'\u001b[0m,\n",
       "                \u001b[32m'function'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"latitude\":22.3433,\"longitude\":91.8333\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'name'\u001b[0m: \u001b[32m'get_weather'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'type'\u001b[0m: \u001b[32m'function'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m79\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m943\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m1022\u001b[0m,\n",
       "            \u001b[32m'completion_time'\u001b[0m: \u001b[1;36m0.065833333\u001b[0m,\n",
       "            \u001b[32m'prompt_time'\u001b[0m: \u001b[1;36m0.113803877\u001b[0m,\n",
       "            \u001b[32m'queue_time'\u001b[0m: \u001b[1;36m0.020066641999999996\u001b[0m,\n",
       "            \u001b[32m'total_time'\u001b[0m: \u001b[1;36m0.17963721\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'llama3-8b-8192'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[32m'fp_6a6771ae9c'\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'tool_calls'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-55abe07f-cc47-427a-b237-7a004564bf7c-0'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'get_weather'\u001b[0m,\n",
       "            \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'latitude'\u001b[0m: \u001b[1;36m22.3433\u001b[0m, \u001b[32m'longitude'\u001b[0m: \u001b[1;36m91.8333\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'id'\u001b[0m: \u001b[32m'call_htsq'\u001b[0m,\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'tool_call'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m943\u001b[0m, \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m79\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m1022\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rich\n",
    "rich.print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": \"Ok, let me check.\"\n",
    "})\n",
    "\n",
    "# Step 3: Make the tool call to get weather information (using the weather API)\n",
    "tool_calls = completion.additional_kwargs['tool_calls']\n",
    "tool_call = tool_calls[0]  # Get the first tool call from the response\n",
    "args = json.loads(tool_call['function']['arguments'])  # Extract arguments\n",
    "latitude = args[\"latitude\"]\n",
    "longitude = args[\"longitude\"]\n",
    "\n",
    "# Get the weather data\n",
    "result = get_weather(latitude, longitude)\n",
    "temperature = result  # For example, you get 26.4°C\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Assistant gives the final result: \"The current temperature in Chittagong is 26.4°C.\"\n",
    "messages.append({\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call['id'],\n",
    "    \"content\": f\"The current temperature in Chittagong is {temperature}°C.\"\n",
    "})\n",
    "\n",
    "# Step 5: Invoke the model again with updated messages\n",
    "completion_2 = client.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'tool_calls'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_e3am'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"latitude\":22.3333,\"longitude\":91.8167}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'get_weather'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">990</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1069</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.065833333</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.122753862</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'queue_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17785026400000004</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.188587195</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llama3-8b-8192'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fp_a97cfe35ae'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool_calls'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-a72066b4-0889-4f89-9cc4-4ca0f7907e3f-0'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'get_weather'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'latitude'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.3333</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'longitude'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91.8167</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_e3am'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool_call'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">990</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1069</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'tool_calls'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'id'\u001b[0m: \u001b[32m'call_e3am'\u001b[0m,\n",
       "                \u001b[32m'function'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"latitude\":22.3333,\"longitude\":91.8167\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'name'\u001b[0m: \u001b[32m'get_weather'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'type'\u001b[0m: \u001b[32m'function'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m79\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m990\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m1069\u001b[0m,\n",
       "            \u001b[32m'completion_time'\u001b[0m: \u001b[1;36m0.065833333\u001b[0m,\n",
       "            \u001b[32m'prompt_time'\u001b[0m: \u001b[1;36m0.122753862\u001b[0m,\n",
       "            \u001b[32m'queue_time'\u001b[0m: \u001b[1;36m0.17785026400000004\u001b[0m,\n",
       "            \u001b[32m'total_time'\u001b[0m: \u001b[1;36m0.188587195\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'llama3-8b-8192'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[32m'fp_a97cfe35ae'\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'tool_calls'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-a72066b4-0889-4f89-9cc4-4ca0f7907e3f-0'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'get_weather'\u001b[0m,\n",
       "            \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'latitude'\u001b[0m: \u001b[1;36m22.3333\u001b[0m, \u001b[32m'longitude'\u001b[0m: \u001b[1;36m91.8167\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'id'\u001b[0m: \u001b[32m'call_e3am'\u001b[0m,\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'tool_call'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m990\u001b[0m, \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m79\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m1069\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Print the result of the second invocation\n",
    "rich.print(completion_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"What's the weather like in Chittagong today?\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Ok, let me check.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'tool_call_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_htsq'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The current temperature in Chittagong is 24.6°C.'</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"What's the weather like in Chittagong today?\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'Ok, let me check.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'tool'\u001b[0m, \u001b[32m'tool_call_id'\u001b[0m: \u001b[32m'call_htsq'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'The current temperature in Chittagong is 24.6°C.'\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the messages content (for debugging purposes)\n",
    "rich.print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the weather like in Chittagong today?\n",
      "Ok, let me check.\n",
      "The current temperature in Chittagong is 24.6°C.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the messages to print their contents\n",
    "for message in messages:\n",
    "    if isinstance(message, dict):\n",
    "        print(message['content'])  # If it's a dictionary\n",
    "    else:\n",
    "        print(message.content)  # If it's an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"What's the weather like in Chittagong today?\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Ok, let me check.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'tool_call_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_htsq'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The current temperature in Chittagong is 24.6°C.'</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"What's the weather like in Chittagong today?\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'Ok, let me check.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'tool'\u001b[0m, \u001b[32m'tool_call_id'\u001b[0m: \u001b[32m'call_htsq'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'The current temperature in Chittagong is 24.6°C.'\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(messages))  # To see whether message is a dict or an object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(template= \"Write a joke about {category}\", input_variable = [\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the programmer quit his job?\\n\\nBecause he didn't get arrays! (get a raise)\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | client\n",
    "response = chain.invoke({\"category\": \"computer science\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"setup\": {\"description\": \"The setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "jokes(setup='Why do programmers prefer dark mode?', punchline='Because light attracts bugs')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class jokes(BaseModel):\n",
    "    setup: str = Field(description= \"The setup of the joke\")\n",
    "    punchline: str = Field(description= \"The punchline of the joke\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object= jokes)\n",
    "print(output_parser.get_format_instructions())\n",
    "\n",
    "prompt = PromptTemplate(template= \"Write a joke about {category}, {formatted_instruction}\", input_variable = [\"category\"],partial_variables={\"formatted_instruction\": output_parser.get_format_instructions()})\n",
    "chain = prompt | llm | output_parser\n",
    "response: jokes = chain.invoke({\"category\": \"computer science\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = \"\"\"\n",
    "```json\n",
    "{\n",
    "    \"setup\": \"Why did the computer go to the doctor?\",\n",
    "  \"punchline\": \"Because it had a virus.\"\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    \"setup\": \"Why did the computer go to the doctor?\",\n",
    "    \"punchline\": \"Because it had a virus.\"\n",
    "}\n",
    "\n",
    "pydantic_data = jokes(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Because it had a virus.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydantic_data.setup\n",
    "pydantic_data.punchline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jokes(setup='What do you call a fake noodle?', punchline='An impasta!')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_output_model = client.with_structured_output(schema= jokes)\n",
    "\n",
    "structured_output_model.invoke(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divides a and b.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = client.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_b5qz', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_5sf9', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [SystemMessage(\"\"),\n",
    "            HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='36' name='multiply' tool_call_id='call_b5qz'\n",
      "content='60' name='add' tool_call_id='call_5sf9'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_b5qz', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_5sf9', 'function': {'arguments': '{\"a\":11,\"b\":49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 2119, 'total_tokens': 2244, 'completion_time': 0.104166667, 'prompt_time': 0.257093326, 'queue_time': -0.37254828500000003, 'total_time': 0.361259993}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cff398dc-f371-43f3-a57f-1a291a81525c-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_b5qz', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_5sf9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2119, 'output_tokens': 125, 'total_tokens': 2244}),\n",
       " ToolMessage(content='36', name='multiply', tool_call_id='call_b5qz'),\n",
       " ToolMessage(content='60', name='add', tool_call_id='call_5sf9')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    print(tool_msg)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 3 * 12 is 36. The answer to 11 + 49 is 60. Therefore, the answer to what is 3 * 12 and what is 11 + 49 is 36 and 60.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(AIMessage(content= response.content))\n",
    "\n",
    "\n",
    "messages.append(HumanMessage(\"What is 3 * 12?\"))\n",
    "response = llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{})</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is 3 * 12? Also, what is 11 + 49?'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{})</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'tool_calls'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_b5qz'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"a\":3,\"b\":12}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'multiply'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_5sf9'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"a\":11,\"b\":49}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'add'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">]</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">125</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2119</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2244</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'completion_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.104166667</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.257093326</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'queue_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.37254828500000003</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.361259993</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llama3-8b-8192'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fp_6a6771ae9c'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool_calls'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-cff398dc-f371-43f3-a57f-1a291a81525c-0'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'multiply'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'b'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_b5qz'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool_call'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'add'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'b'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_5sf9'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tool_call'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2119</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">125</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2244</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ToolMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'36'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'multiply'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_call_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'call_b5qz'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ToolMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'60'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'add'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_call_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'call_5sf9'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The answer to 3 * 12 is 36. The answer to 11 + 49 is 60. Therefore, the answer to what is 3 * 12 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and what is 11 + 49 is 36 and 60.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is 3 * 12?'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{})</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mSystemMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'What is 3 * 12? Also, what is 11 + 49?'\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'tool_calls'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'id'\u001b[0m: \u001b[32m'call_b5qz'\u001b[0m,\n",
       "                    \u001b[32m'function'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"a\":3,\"b\":12\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'name'\u001b[0m: \u001b[32m'multiply'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'type'\u001b[0m: \u001b[32m'function'\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'id'\u001b[0m: \u001b[32m'call_5sf9'\u001b[0m,\n",
       "                    \u001b[32m'function'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"a\":11,\"b\":49\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'name'\u001b[0m: \u001b[32m'add'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'type'\u001b[0m: \u001b[32m'function'\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m]\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m125\u001b[0m,\n",
       "                \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m2119\u001b[0m,\n",
       "                \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m2244\u001b[0m,\n",
       "                \u001b[32m'completion_time'\u001b[0m: \u001b[1;36m0.104166667\u001b[0m,\n",
       "                \u001b[32m'prompt_time'\u001b[0m: \u001b[1;36m0.257093326\u001b[0m,\n",
       "                \u001b[32m'queue_time'\u001b[0m: \u001b[1;36m-0.37254828500000003\u001b[0m,\n",
       "                \u001b[32m'total_time'\u001b[0m: \u001b[1;36m0.361259993\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'model_name'\u001b[0m: \u001b[32m'llama3-8b-8192'\u001b[0m,\n",
       "            \u001b[32m'system_fingerprint'\u001b[0m: \u001b[32m'fp_6a6771ae9c'\u001b[0m,\n",
       "            \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'tool_calls'\u001b[0m,\n",
       "            \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'run-cff398dc-f371-43f3-a57f-1a291a81525c-0'\u001b[0m,\n",
       "        \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'multiply'\u001b[0m, \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'a'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'b'\u001b[0m: \u001b[1;36m12\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'id'\u001b[0m: \u001b[32m'call_b5qz'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'tool_call'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'add'\u001b[0m, \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'a'\u001b[0m: \u001b[1;36m11\u001b[0m, \u001b[32m'b'\u001b[0m: \u001b[1;36m49\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'id'\u001b[0m: \u001b[32m'call_5sf9'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'tool_call'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m2119\u001b[0m, \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m125\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m2244\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mToolMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'36'\u001b[0m, \u001b[33mname\u001b[0m=\u001b[32m'multiply'\u001b[0m, \u001b[33mtool_call_id\u001b[0m=\u001b[32m'call_b5qz'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mToolMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'60'\u001b[0m, \u001b[33mname\u001b[0m=\u001b[32m'add'\u001b[0m, \u001b[33mtool_call_id\u001b[0m=\u001b[32m'call_5sf9'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'The answer to 3 * 12 is 36. The answer to 11 + 49 is 60. Therefore, the answer to what is 3 * 12 \u001b[0m\n",
       "\u001b[32mand what is 11 + 49 is 36 and 60.'\u001b[0m,\n",
       "        \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'What is 3 * 12?'\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
